# Peer Response 2

---

Hello Rodrigo,

Your exploration of LLM limitations, such as hallucination and lack of transparency, is excellent. I’d like to further examine the implications of corporate dominance in AI. As you mentioned, the reluctance of tech giants like OpenAI and Microsoft to disclose training datasets raises accountability issues. This lack of transparency could hinder not only public trust but also efforts to improve AI systems through collaborative oversight (Mitchell, 2019).

Interestingly, research shows that monopolistic control in AI can also add to biases. When corporate giants dominate the field, smaller competitors struggle to introduce alternative models that may address persistent issues like bias and hallucination (von Thun, 2024). Additionally, these companies’ political affiliations can impact AI’s applications, as seen in cases of misinformation tied to electoral processes (Csernatoni, 2024).

Do you think increased regulatory oversight, such as the EU AI Act’s transparency requirements, could level the playing field and foster innovation among smaller AI developers? - I would be interested to know your thoughts.

---

## References:

Mitchell, M. (2019) Artificial Intelligence: A Guide for Thinking Humans. London: Pelican Books.

von Thun, M. (2024) ‘Monopolies Are to Blame for Generative AI's Hallucinations’, Project Syndicate. Available at: https://www.project-syndicate.org/commentary/big-tech-monopolies-to-blame-for-unreliable-unsafe-generative-ai-by-max-von-thun-2024-07 (Accessed: 16 January 2025).

Csernatoni, R. (2024) ‘Can Democracy Survive the Disruptive Power of AI?’, Carnegie Endowment. Available at: https://carnegieendowment.org/research/2024/12/can-democracy-survive-the-disruptive-power-of-ai?lang=en (Accessed: 16 January 2025).
