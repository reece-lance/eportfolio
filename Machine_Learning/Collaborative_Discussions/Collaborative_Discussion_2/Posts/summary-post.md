# Summary Post

---

Over the past weeks, the discussion on AI writers has revealed their transformative potential alongside significant risks. My initial post highlighted benefits such as enhanced productivity, inclusivity for non-native speakers, and creative outputs (Hutson, 2021; Jenni AI, 2024). However, I also emphasised risks like embedded biases, ethical misuse, and the erosion of creativity and critical thinking.

Feedback from peers expanded these ideas. Panagiotis Mourtas stressed the importance of human oversight, particularly in verifying outputs for sensitive tasks. Yuji Watanabe highlighted AI’s cost-efficiency and 24/7 capabilities while cautioning against over-reliance, particularly in high-stakes fields like medicine and law. This aligns with research that suggests integrating verified knowledge bases to improve reliability.

Rodrigo Pereira Cruz raised concerns about corporate dominance in AI, noting how monopolistic control stifles innovation and exacerbates biases (von Thun, 2024). This links to transparency issues, as companies often refuse to disclose training datasets, hindering collaborative oversight and public trust. Regulatory frameworks like the EU AI Act could help address these issues by enforcing greater transparency (Coulter, 2024).

The course content reinforced these discussions, particularly on the role of ethical innovation. Approaches such as Reinforcement Learning with Human Feedback (RLHF) offer potential for aligning AI with human values but remain resource-intensive and incomplete (Murata et al., 2024). Units 8, 9 and 10 also emphasised societal adaptability, as over-reliance on AI could erode critical thinking and creativity if safeguards are not in place (Mondal and Mondal, 2023).

In conclusion, AI writers offer immense benefits but must complement, not replace, human creativity and decision-making. Transparency, ethical guidelines, and balanced regulation are essential for their responsible development and use.

---

## References

Coulter, M. (2024) 'EU's new AI rules ignite battle over data transparency', Reuters. Available at: https://www.reuters.com/technology/artificial-intelligence/eus-new-ai-rules-ignite-battle-over-data-transparency-2024-06-13/ (Accessed: 16 January 2025).

Hutson, M. (2021) Robo-writers: The rise and risks of language-generating AI. Nature. Available at: https://www.nature.com/articles/d41586-021-00530-0 (Accessed: 16 January 2025).

Jenni AI (2024) 'The Impact of AI on Writing: Efficiency, Accuracy, and Beyond'. Available at: https://jenni.ai/artificial-intelligence/writing-benefits (Accessed: 16 January 2025).

Mondal, H. and Mondal, S. (2023) ‘ChatGPT in academic writing: Maximising its benefits and minimising the risks’, Indian Journal of Ophthalmology, 71(12), pp. 3600–3606. Available at: https://doi.org/10.4103/IJO.IJO_718_23.

Murata, T., Mori, N. & Makoto, O. (2024) 'Learning Methods for LLMs on Game Data Using RLHF', 2024 National Conference of the Society for Artificial Intelligence. Hamamatsu, 28-31 May. Tokyo: Society for Artificial Intelligence.

von Thun, M. (2024) ‘Monopolies Are to Blame for Generative AI's Hallucinations’, Project Syndicate. Available at: https://www.project-syndicate.org/commentary/big-tech-monopolies-to-blame-for-unreliable-unsafe-generative-ai-by-max-von-thun-2024-07 (Accessed: 16 January 2025).
