# Collaborative Discussion Summary: Dark UX Patterns and Ethical Conduct

---

## Overview

This discussion took place across Units 1 to 3 and focused on analysing ethical responsibilities in computing, guided by the ACM Code of Ethics and the BCS Code of Conduct. The selected case study, "Dark UX Patterns", examined unethical design practices that mislead users through deceptive visual or interaction design. I explored the professional, legal, and social implications of such practices, contributing an initial post, multiple peer responses, and a summary reflection.

---

## Discussion Topic

**Case Study Chosen**: Dark UX Patterns (ACM, n.d.)

**Focus**: Application of the ACM and BCS codes of conduct to unethical user interface design. Emphasis was placed on the ethical obligations of computing professionals, organisational accountability, legal frameworks, and user trust.

---

## My Posts

- [Initial Post – Ethical Implications of Dark UX Patterns](./Posts/initial-post.md)
- [Peer Response 1](./Posts/peer-response1.md)
- [Peer Response 2](./Posts/peer-response2.md)
- [Summary Post](./Posts/summary-post.md)

---

## Key Themes and Reflections

### Ethical Considerations

- I referenced ACM principles on harm avoidance, honesty, and fairness (1.1–1.4), arguing that dark UX practices breach these codes by misleading users and undermining trust.
- BCS codes were used to demonstrate failure to uphold accessibility and transparency, particularly around public welfare and equal access to IT.
- Peer feedback, especially from Christopher and Anda, reinforced the importance of whistleblowing and standardised ethical design frameworks within organisations.

### Legal and Social Implications

- Discussions cited the **Consumer Protection from Unfair Trading Regulations (2008)** and the **Equality Act (2010)** as relevant legislation violated by deceptive UX strategies.
- I introduced the **UK Digital Markets, Competition and Consumer Bill (2023)** and recent **FTC crackdowns** on dark patterns, noting that legal enforcement often struggles to keep pace with evolving manipulation tactics.
- Several peers, including Anda and Mohammed, expanded the scope to **AI-driven manipulation**, noting that future regulation must also address machine learning systems nudging user decisions.

### Professionalism and Accountability

- We explored the role of internal ethical review boards and whistleblowing protections to support ethical resistance in corporate settings.
- I advocated for a positive use of AI in enhancing transparency rather than exploiting user behaviour — building systems that guide rather than deceive.

### Critical Engagement and Literature Used

- Across my posts and responses, I integrated a range of sources including the ACM/BCS codes, academic articles on UX and AI ethics (e.g., Gray et al., 2018; Petropoulos, 2022), and legislation from both UK and EU contexts.
- Norman & Nielsen’s (2020) “The Design of Everyday Things” was referenced to justify how design psychology plays a central role in user trust and manipulation.

---

## Evaluation

This discussion reinforced my understanding of the ethical frameworks guiding professional computing practice. It sharpened my ability to connect design decisions to legal frameworks, critically assess professional responsibility, and respond to peer perspectives constructively. I also developed a more nuanced appreciation of the blurred boundaries between UI design, user psychology, and AI-driven systems.

---

## References (included in full in posts)

- ACM (2018). *Code of Ethics and Professional Conduct*
- BCS (2022). *Code of Conduct for BCS Members*
- UK Government (2008). *Consumer Protection from Unfair Trading Regulations*
- W3C (2018). *Web Content Accessibility Guidelines*
- FTC (2022). *Bringing Dark Patterns to Light*
- Moore (2024), Petropoulos (2022), Schaareman (2023), Gray et al. (2018), Cooper et al. (2014)
